

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>5. Configuration file and examples &#8212; Handbook</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/05-config';</script>
    <link rel="shortcut icon" href="../_static/favicon_32.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="6. Profile cells with DeepProfiler" href="06-profiling.html" />
    <link rel="prev" title="4. Metadata and single-cell locations" href="04-metadata.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="00-welcome.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/banner.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/banner.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="00-welcome.html">
                    Welcome to DeepProfiler
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01-install.html">1. Install DeepProfiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="02-structure.html">2. Project structure</a></li>
<li class="toctree-l1"><a class="reference internal" href="03-images.html">3. Images and segmentation masks</a></li>
<li class="toctree-l1"><a class="reference internal" href="04-metadata.html">4. Metadata and single-cell locations</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">5. Configuration file and examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="06-profiling.html">6. Profile cells with DeepProfiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="07-train.html">7. Training models with DeepProfiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="08-process.html">8. Downstream analysis</a></li>


</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/cytomining/DeepProfiler-handbook" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/cytomining/DeepProfiler-handbook/edit/main/DeepProfiler-Handbook/docs/05-config.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/cytomining/DeepProfiler-handbook/issues/new?title=Issue%20on%20page%20%2Fdocs/05-config.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/docs/05-config.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>5. Configuration file and examples</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration-file-organization">5.1 Configuration File Organization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-description-of-your-image-collection-with-basic-general-information">1. <code class="docutils literal notranslate"><span class="pre">dataset</span></code>: description of your image collection with basic general information</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-configuration-for-illumination-correction-and-compression">2. <code class="docutils literal notranslate"><span class="pre">prepare</span></code>: configuration for illumination correction and compression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#code-profile-code-parameters-to-run-an-existing-model-on-images-to-extract-features-or-obtain-classification-outputs">3. <code>profile</code>: parameters to run an existing model on images to extract features or obtain classification outputs.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-parameters-for-training-a-deep-learning-model-on-your-data">4. <code class="docutils literal notranslate"><span class="pre">train</span></code>: parameters for training a deep learning model on your data.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#available-examples-of-configuration-files">5.2 Available examples of configuration files</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="configuration-file-and-examples">
<h1>5. Configuration file and examples<a class="headerlink" href="#configuration-file-and-examples" title="Permalink to this heading">#</a></h1>
<p>The configuration file is a text file in JSON format that organizes various settings for one experiment. If you need to
test different configurations, you can create different configuration files and run DeepProfiler with each. DeepProfiler
searches for the configuration file in the <code class="docutils literal notranslate"><span class="pre">inputs/config/</span></code> directory, which you can use to store various configuration files.
Note that the <code class="docutils literal notranslate"><span class="pre">--config</span></code> flag does not need you to specify the full path of the file, just the name as it is assumed to be
stored in the <code class="docutils literal notranslate"><span class="pre">inputs/config/</span></code> directory.</p>
<section id="configuration-file-organization">
<h2>5.1 Configuration File Organization<a class="headerlink" href="#configuration-file-organization" title="Permalink to this heading">#</a></h2>
<p>The configuration file is organized into four main sections as follows. We’ve included specific recommendations where possible.
For more details, check out our <a class="reference external" href="https://www.biorxiv.org/content/10.1101/2022.08.12.503783v2">preprint</a>. For generating this config file for your project, look at the descriptions
below together with the provided examples of metadata and configuration files.</p>
<section id="dataset-description-of-your-image-collection-with-basic-general-information">
<h3>1. <code class="docutils literal notranslate"><span class="pre">dataset</span></code>: description of your image collection with basic general information<a class="headerlink" href="#dataset-description-of-your-image-collection-with-basic-general-information" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">metadata</span></code></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">label_field</span></code>: <em>(string)</em> column in the metadata file corresponding to the treatments or biologically relevant labels of images.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">control_value</span></code>: <em>(string)</em> identifier or name of control samples in the column above (used to gather illumination statistics).</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">images</span></code></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">channels</span></code>: <em>(array of strings)</em> list of image channels used for profiling. The list contains the names of columns in the metadata file that hold the location of images for each channel. DeepProfiler assumes each channel is stored as a separate image, and also that the path listed in the metadata file is relative to the input/images directory (instead of absolute paths). This facilitates moving the project to another machine in a different location.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">file_format</span></code>: <em>(string)</em> extension of image files, e.g. tiff, tif, png.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bits</span></code>: <em>(int)</em> pixel bit depth. Not necessary for any analysis, only used for compression purposes. 8-bit and 16-bit images are currently supported.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">width</span></code>: <em>(int)</em> width of the input image in pixels</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">height</span></code>: <em>(int)</em> height of the input image in pixels</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">locations</span></code>: parameterize how DeepProfiler will search for single cells in images for training and profiling.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">mode</span></code>: <em>(string)</em> this field indicates if images will be processed at single-cell resolution or in full image mode. It only accepts two strings: <code class="docutils literal notranslate"><span class="pre">single_cells</span></code> - activates single-cell analysis mode, thus, requiring cell locations to be stored in the <code class="docutils literal notranslate"><span class="pre">inputs/locations/</span></code> folder (Section XXX); <code class="docutils literal notranslate"><span class="pre">full_image</span></code> - activates full image analysis (no need for locations files).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">box_size</span></code>: <em>(int)</em> specifies the size in pixels of the bounding box used to crop single cells out of images. The value is used for both the width and the height of the box (a square box). This value is used even in <code class="docutils literal notranslate"><span class="pre">full_image</span></code> mode, in which case the image will be resized to these dimensions. Note that DeepProfiler enforces a fixed input size because that is what neural network models usually expect. The box size should be selected to fully cover a typical cell in the experiment. It is OK if large cells are cut a bit, as long as this is relatively rare compared to the normal cell size. Also, it is OK if cells appear with neighboring cells in the same box, which we call “single cells in context” or can be fixed by masking (see below).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">view_size</span></code>: <em>(int)</em> useful only in <code class="docutils literal notranslate"><span class="pre">full_image</span></code> mode, specifies the size in pixels of the region of the image to be covered by cropping before resizing to the dimensions configured in <code class="docutils literal notranslate"><span class="pre">box_size</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mask_objects</span></code>: <em>(bool)</em> true or false, indicates whether cells should be masked using the cell outlines in <code class="docutils literal notranslate"><span class="pre">input/outlines</span></code>. Optional, the recommended value at the moment is false (see more information below).</p></li>
</ul>
</li>
</ul>
</section>
<section id="prepare-configuration-for-illumination-correction-and-compression">
<h3>2. <code class="docutils literal notranslate"><span class="pre">prepare</span></code>: configuration for illumination correction and compression<a class="headerlink" href="#prepare-configuration-for-illumination-correction-and-compression" title="Permalink to this heading">#</a></h3>
<p>The command <code class="docutils literal notranslate"><span class="pre">prepare</span></code> then runs illumination correction and compression, useful for preparing training datasets that can be read efficiently repeated times from disk. This is optional if you only need to do feature extraction and profiling with a pre-trained model.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">illumination_correction</span></code>: parameters to run a prospective illumination correction algorithm that estimates the illumination correction functions for each channel in each plate.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">down_scale_factor</span></code>: <em>(float)</em> the illumination correction functions are not computed at full resolution. This parameter tells DeepProfiler how small these functions should be. A common parameter is 4, for images of about 1024x1024 pixels, resulting in illumination correction functions of 256x256 pixels.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">median_filter_size</span></code>: <em>(int)</em> size in pixels of the smoothing operator applied before aggregation of the illumination correction function. Usually set to 24 for images of 1024x1024 pixels.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">compression</span></code>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">implement</span></code>: <em>(bool)</em> true or false, whether compression is used for training and profiling. If true, other DeepProfiler commands will use the compressed images in the <code class="docutils literal notranslate"><span class="pre">output/compressed/</span></code> directory instead of the original images in the <code class="docutils literal notranslate"><span class="pre">input/images/</span></code> directory.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scaling_factor</span></code>: <em>(float)</em> make images a fraction of what they are. 1.0 means no scaling, 0.8 means resizing to 80% of the current size in <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>. Re-scaling images results in smaller files that are faster to read during training, but loses spatial resolution, which is generally not recommended. Use a value different to 1.0 only if there is a good experimental reason.</p></li>
</ul>
</li>
</ul>
</section>
<section id="code-profile-code-parameters-to-run-an-existing-model-on-images-to-extract-features-or-obtain-classification-outputs">
<h3>3. <code>profile</code>: parameters to run an existing model on images to extract features or obtain classification outputs.<a class="headerlink" href="#code-profile-code-parameters-to-run-an-existing-model-on-images-to-extract-features-or-obtain-classification-outputs" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><code>use_pretrained_input_size</code>: <em>(int)</em> input size for the neural network models pre-trained on the ImageNet dataset. The pre-trained InceptionResNetv2 model uses <code>299</code> while pre-trained ResNet and EfficientNet models use <code>224</code>. This parameter is not needed for models trained by you, only for these three supported pre-trained models.</p></li>
<li><p><code>feature_layer</code>: <em>(string)</em> name of the layer in the convolutional network to be used for feature extraction.</p></li>
<li><p><code>checkpoint</code>: <em>(string)</em> name of the weights file stored in the <code>outputs/&lt;experiment&gt;/checkpoint/</code> directory after the network is trained.</p></li>
<li><p><code>batch_size</code>: <em>(int)</em> number of samples used during the forward pass for feature extraction.</p></li>
</ul>
</section>
<section id="train-parameters-for-training-a-deep-learning-model-on-your-data">
<h3>4. <code class="docutils literal notranslate"><span class="pre">train</span></code>: parameters for training a deep learning model on your data.<a class="headerlink" href="#train-parameters-for-training-a-deep-learning-model-on-your-data" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">partition</span></code>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">targets</span></code>: <em>(array)</em> column names in the metadata file that want to be used as classification targets for training the neural networks. It currently uses only the first element in the list, e.g., <code class="docutils literal notranslate"><span class="pre">['Compound',</span> <span class="pre">'Concentration']</span></code>, means that there are two columns in the metadata file with that information and that DeepProfiler will use <code class="docutils literal notranslate"><span class="pre">'Compound'</span></code> for training. The rest of the array is currently ignored but is intended to be used in the future. If both columns are necessary for training, consider merging them in a single column, otherwise, you can leave only one column name in the array i.e., <code class="docutils literal notranslate"><span class="pre">['Compound']</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">split_field</span></code>: <em>(string)</em> column name in the metadata file that indicates which images should be used for training and which ones for validation (or just ignored). This column may be one of the columns containing information about the experiment (e.g. plate id) or a custom-defined column with these decisions made by the analysis.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">training</span></code>: <em>(array)</em> unique values in the <code class="docutils literal notranslate"><span class="pre">split_field</span></code> column of the metadata file that indicate which images will be used for training. For example, if <code class="docutils literal notranslate"><span class="pre">split_field=Metadata_Plate</span></code>, this array should indicate which plates are intended to used for training e.g. <code class="docutils literal notranslate"><span class="pre">[&quot;plateA&quot;,</span> <span class="pre">&quot;plateB&quot;,</span> <span class="pre">&quot;plateC&quot;]</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">validation</span></code>: <em>(array)</em> unique values in the <code class="docutils literal notranslate"><span class="pre">split_field</span></code> column of the metadata file that indicate which images will be used for validation. This is the same as the <code class="docutils literal notranslate"><span class="pre">training</span></code> field above.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">model</span></code>: deep learning model parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: <em>(string)</em> deep learning model to be used, the name should be one of the models in the plugins folder. The default recommended model is <code class="docutils literal notranslate"><span class="pre">efficientnet</span></code> for weakly supervised learning. We also support <code class="docutils literal notranslate"><span class="pre">resnet</span></code> models.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">crop_generator</span></code>: <em>(string)</em> strategy for cropping single cells from images. Crop generators are implemented in the plugins folder and can be extended with custom code if necessary. DeepProfiler currently has the following options implemented: 1) <code class="docutils literal notranslate"><span class="pre">sampled_crop_generator</span></code>, this crop generator reads single-cell images pre-cropped and exported for training (see Section XXX). This is the recommended way for training new models.  2) <code class="docutils literal notranslate"><span class="pre">online_labels_cropgen</span></code>, used for training with online label smoothing using exported single-cell datasets as before. If analyzing the dataset in full_image mode, you should use the default value. 3) <code class="docutils literal notranslate"><span class="pre">repeat_channel_crop_generator</span></code>, used for extracting features using networks pre-trained with the ImageNet dataset (RGB natural images). This crop generator transforms each gray-scale channel of your images into an RGB image to enable processing and then concatenates the features of all channels in a single vector. This crop generator is only useful for profiling and should not be used for training. It can be used in <code class="docutils literal notranslate"><span class="pre">full_image</span></code> analysis mode. 4)  <code class="docutils literal notranslate"><span class="pre">full_image_crop_generator</span></code>, used for training new models and profiling in full image mode.</p></li>
<li><p><code>augmentations</code>: <em>(boolean)</em> </code>switch augmentation layer on and off. DeepProfiler uses data augmentation to generate models robust to certain transformations and noise. The transformations implemented in the augmentation layer are applied at random to images of single cells during training only and include 90-degree rotations, horizontal flips, brightness and contrast illumination perturbations on each channel separately.</p></li>
<li><p><code>metrics</code>: <em>(array of strings)</em> contains names of metrics to monitor performance during training. It supports most of the <a class="reference external" href="https://keras.io/api/metrics/">keras metrics</a>, including <code>accuracy</code>. This applies for now only for the <code>train</code> command.</p></li>
<li><p><code>epochs</code>: <em>(int)</em> number of epochs for training.</p></li>
<li><p><code>initialization</code>: <em>(string)</em> strategy to set the initial model weights for training. Valid values are <code>Random</code> (supported by all models) or <code>ImageNet</code> (currently supported by ResNet and EfficientNet models only). Using ImageNet weights is a better initialization strategy in practice, and usually leads to improved performance.</p></li>
<li><p><code>checkpoint_policy</code>: <em>(string)</em> or <em>(int)</em> checkpointing policy parameter (optional). Checkpoints are files that save the state of the model during training because training sessions are usually long and may fail (or be interrupted by the system). Checkpoints help to recover the training session, or simply reuse the model after training. If the parameter is an integer number, then DeepProfiler saves model checkpoints every <code>checkpoint_policy</code> step. If the string <code>best</code> is used, then DeepProfiler saves only the best-performed checkpoint according to validation performance. By default, checkpoints are saved for every epoch.</p></li>
<li><p><code>params</code>: model-specific values that depend on the plugin or architecture.</p>
<ul>
<li><p><code>learning_rate</code>: <em>(float)</em> initial learning rate for the optimizer.</p></li>
<li><p><code>batch_size</code>: <em>(int)</em> number of samples per batch during training.</p></li>
<li><p><code>conv_blocks</code>: <em>(int)</em> number of layers, or convolutional blocks. For ResNet valid values only include <code>50</code>, <code>101</code> and <code>152</code>.</p></li>
<li><p><code>label_smoothing</code>:<code> </code>(<em>float</em>) label smoothing parameter for categorical cross-entropy loss.</p></li>
<li><p><code>online_label_smoothing:</code>(<em>float</em>) label smoothing if online labeling is used.</p></li>
<li><p><code>online_lambda:</code> (<em>float</em>) online labeling regularization parameter.</p></li>
</ul>
</li>
<li><p><code>lr_schedule</code>: <em>(array or string)</em> strategy for decreasing the learning rate during training. There are three strategies supported:</p>
<ul>
<li><ol class="arabic simple">
<li><p>constant rate, which doesn’t require this parameter to be set (i.e. just remove this parameter from the config file).</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="2">
<li><p>step schedule: changes the learning rate to a desired value at specific epochs. This strategy needs you to configure two arrays, ”epoch” for the epochs where the learning rate will be changed (integer numbers), and “lr” with the actual desired learning rate values (e.g. <code>{“epoch”:[40, 80], “lr”:[0.1, 0.01]}</code>). Both arrays are expected to be the same size.</p></li>
</ol>
</li>
<li><ol class="arabic simple" start="3">
<li><p>cosine decay, which increments the learning rate from zero to the initial learning rate using a linear function during the first five epochs. After that, every epoch reduces the learning rate according to the cosine decay. Use <code>”cosine”</code> to enable this option.</p></li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
<li><p><code>sampling</code>: parameters to load images and crop single cells during training. Those parameters are only used for the default <code>crop_generator</code> (<code>”crop_generator”)</code>, which is used for exporting single cells, among others.</p>
<ul>
<li><p><code>factor</code>: <em>(float)</em> fraction of crops from each image to be used for training (number between 0 and 1). This parameter can be used to prevent filling up the queue with example cells from a few images only. With a small sampling factor, the queue will have more diversity of cells cropped from a variety of images to create batches, improving the training performance. In this case, more epochs will be needed to reach optimal performance.</p></li>
<li><p><code>cache_size</code>: <em>(int)</em> number of examples to keep in memory from the sampling process. The larger the better to ensure diversity of examples for creating training batches. This needs to be set according to hardware capabilities, the number of channels, box size, etc.</p></li>
<li><p><code>workers</code>: <em>(int)</em> number of parallel loading processes that read images, crop single cells and put them in the queue for training.</p></li>
</ul>
</li>
<li><p><code>validation</code>: parameters for experimental evaluation.</p>
<ul>
<li><p><code>frequency</code>: <em>(int)</em> number of epochs to run before running one validation evaluation.</p></li>
<li><p><code>top_k</code>: <em>(int)</em> reports an accuracy metric where the correct answer is in the top K choices.</p></li>
<li><p><code>batch_size</code>: <em>(int)</em> batch size for the validation set.</p></li>
<li><p><code>frame</code>: <em>(string)</em> partition of the data used for validation. Valid values include “all”, “train” or “val”. Recommended default value: “val”.</p></li>
<li><p><code>sample_first_crops</code>: <em>(bool)</em> true or false, whether to use all crops from each validation image or only sample the first N for validation, where N is the batch size.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="available-examples-of-configuration-files">
<h2>5.2 Available examples of configuration files<a class="headerlink" href="#available-examples-of-configuration-files" title="Permalink to this heading">#</a></h2>
<p>The examples of configuration files can be found in the <a class="reference external" href="https://cytomining.github.io/DeepProfiler-handbook/docs/02-structure.html#add-project-data">example data</a>,
<a class="reference external" href="https://github.com/cytomining/DeepProfiler/blob/master/example_data.tar.gz">availible in DeepProfiler repository</a>
under <code class="docutils literal notranslate"><span class="pre">/inputs/config/</span></code> folder. It contains two examples:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">training_profiling.json</span></code>: a configuration file for <a class="reference external" href="https://cytomining.github.io/DeepProfiler-handbook/docs/07-train.html">training</a>
with the example data and then <a class="reference external" href="https://cytomining.github.io/DeepProfiler-handbook/docs/06-profiling.html#profiling-with-self-trained-model">profiling</a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">export.json</span></code>: a configuration file for <a class="reference external" href="https://cytomining.github.io/DeepProfiler-handbook/docs/07-train.html#export-single-cells">single-cell export</a>.</p></li>
</ol>
<p><a class="reference external" href="https://github.com/broadinstitute/DeepProfilerExperiments">DeepProfilerExperiments Github repository</a> contains
experiment configuration files for the benchmark datasets (in the repository you can find a corresponding folder for
each of those: <code class="docutils literal notranslate"><span class="pre">ta-orf</span></code> (BBBC037 dataset), <code class="docutils literal notranslate"><span class="pre">bbbc022</span></code> and <code class="docutils literal notranslate"><span class="pre">cdrp</span></code> (BBBC036 dataset)) the example configuration files
can be found in the <code class="docutils literal notranslate"><span class="pre">config</span></code> folder. There are the following examples:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">cell_painting_cnn.json</span></code>: a configuration file for <a class="reference external" href="https://cytomining.github.io/DeepProfiler-handbook/docs/06-profiling.html#profiling-with-cell-painting-cnn-model">profiling with the <em>Cell Painting CNN</em> model</a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">efficientnet_train_and_profile.json</span></code>: a configuration file for <a class="reference external" href="https://cytomining.github.io/DeepProfiler-handbook/docs/07-train.html">training</a> and then <a class="reference external" href="https://cytomining.github.io/DeepProfiler-handbook/docs/06-profiling.html#profiling-with-self-trained-model">profiling</a> with the trained model.
It does not differ much from the previous one, only the name of the checkpoint file is different.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">export.json</span></code>: a configuration file for <a class="reference external" href="https://cytomining.github.io/DeepProfiler-handbook/docs/07-train.html#export-single-cells">single-cell export</a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pretrained_effnet.json</span></code>: a configuration file for <a class="reference external" href="https://cytomining.github.io/DeepProfiler-handbook/docs/06-profiling.html#profiling-with-imagenet-pre-trained-model">profiling with ImageNet pre-trained</a> EfficientNet.</p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="04-metadata.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">4. Metadata and single-cell locations</p>
      </div>
    </a>
    <a class="right-next"
       href="06-profiling.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">6. Profile cells with DeepProfiler</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#configuration-file-organization">5.1 Configuration File Organization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-description-of-your-image-collection-with-basic-general-information">1. <code class="docutils literal notranslate"><span class="pre">dataset</span></code>: description of your image collection with basic general information</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prepare-configuration-for-illumination-correction-and-compression">2. <code class="docutils literal notranslate"><span class="pre">prepare</span></code>: configuration for illumination correction and compression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#code-profile-code-parameters-to-run-an-existing-model-on-images-to-extract-features-or-obtain-classification-outputs">3. <code>profile</code>: parameters to run an existing model on images to extract features or obtain classification outputs.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#train-parameters-for-training-a-deep-learning-model-on-your-data">4. <code class="docutils literal notranslate"><span class="pre">train</span></code>: parameters for training a deep learning model on your data.</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#available-examples-of-configuration-files">5.2 Available examples of configuration files</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Michael Bornholdt, Juan Caicedo, Yu Han, Nikita Moshkov, Rebecca Senft (in alphabetical order)
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>