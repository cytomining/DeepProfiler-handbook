
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>5. Configuration file &#8212; Handbook</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/favicon_32.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="6. Training models with DeepProfiler" href="06-train.html" />
    <link rel="prev" title="4. Metadata files" href="04-metadata.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/banner.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Handbook</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="00-welcome.html">
                    Welcome to DeepProfiler
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="01-install.html">
   1. Install DeepProfiler
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="02-structure.html">
   2. Project structure
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="03-images.html">
   3. Images and segmentation masks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="04-metadata.html">
   4. Metadata files
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   5. Configuration file
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="06-train.html">
   6. Training models with DeepProfiler
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="07-profiling.html">
   7. Profile cells with DeepProfiler
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="08-aggregate.html">
   8. Aggregating profiles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="09-process.html">
   9. Processing DeepProfiler features
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/cytomining/DeepProfiler-handbook"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/cytomining/DeepProfiler-handbook/issues/new?title=Issue%20on%20page%20%2Fdocs/05-config.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/cytomining/DeepProfiler-handbook/edit/main/DeepProfiler-Handbook/docs/05-config.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/docs/05-config.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#strong-configuration-file-organization-strong">
   <strong>
    Configuration File Organization
   </strong>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset-description-of-your-image-collection-with-basic-general-information">
     1.
     <code class="docutils literal notranslate">
      <span class="pre">
       dataset
      </span>
     </code>
     : description of your image collection with basic general information
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prepare-configuration-for-illumination-correction-and-compression">
     2.
     <code class="docutils literal notranslate">
      <span class="pre">
       prepare
      </span>
     </code>
     : configuration for illumination correction and compression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-parameters-for-training-a-deep-learning-model-on-your-data">
     3.
     <code class="docutils literal notranslate">
      <span class="pre">
       train
      </span>
     </code>
     : parameters for training a deep learning model on your data.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#code-profile-code-parameters-to-run-an-existing-model-on-images-to-extract-features-or-obtain-classification-outputs">
     4.
     <code>
      profile
     </code>
     : parameters to run an existing model on images to extract features or obtain classification outputs.
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>5. Configuration file</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#strong-configuration-file-organization-strong">
   <strong>
    Configuration File Organization
   </strong>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dataset-description-of-your-image-collection-with-basic-general-information">
     1.
     <code class="docutils literal notranslate">
      <span class="pre">
       dataset
      </span>
     </code>
     : description of your image collection with basic general information
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#prepare-configuration-for-illumination-correction-and-compression">
     2.
     <code class="docutils literal notranslate">
      <span class="pre">
       prepare
      </span>
     </code>
     : configuration for illumination correction and compression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-parameters-for-training-a-deep-learning-model-on-your-data">
     3.
     <code class="docutils literal notranslate">
      <span class="pre">
       train
      </span>
     </code>
     : parameters for training a deep learning model on your data.
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#code-profile-code-parameters-to-run-an-existing-model-on-images-to-extract-features-or-obtain-classification-outputs">
     4.
     <code>
      profile
     </code>
     : parameters to run an existing model on images to extract features or obtain classification outputs.
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="configuration-file">
<h1>5. Configuration file<a class="headerlink" href="#configuration-file" title="Permalink to this headline">#</a></h1>
<p>The configuration file is a text file in JSON format that organizes various settings for one experiment. If you need to test different configurations, you can create different configuration files and run DeepProfiler with each. DeepProfiler searches for the configuration file in the <code class="docutils literal notranslate"><span class="pre">inputs/config/</span></code> directory, which you can use to store various configuration files. Note that the <code class="docutils literal notranslate"><span class="pre">--config</span></code> flag does not need you to specify the full path of the file, just the name as it is assumed to be stored in the <code class="docutils literal notranslate"><span class="pre">inputs/config/</span></code> directory.</p>
<section id="strong-configuration-file-organization-strong">
<h2><strong>Configuration File Organization</strong><a class="headerlink" href="#strong-configuration-file-organization-strong" title="Permalink to this headline">#</a></h2>
<p>The configuration file is organized in four main sections as follows. We’ve included specific recommendations where possible. For more details, check out our paper (link). For generating this config file for your own project, look at the descriptions below together with the provided examples of index.csv and config.json files.</p>
<section id="dataset-description-of-your-image-collection-with-basic-general-information">
<h3>1. <code class="docutils literal notranslate"><span class="pre">dataset</span></code>: description of your image collection with basic general information<a class="headerlink" href="#dataset-description-of-your-image-collection-with-basic-general-information" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">metadata</span></code></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">label_field</span></code>: <em>(string)</em> column in the index.csv file corresponding to the treatments or biologically relevant labels of images.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">control_value</span></code> : <em>(string)</em> identifier or name of control samples in the column above (used to gather illumination statistics).</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">images</span></code></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">channels</span></code>: <em>(array of strings)</em> list of image channels used for profiling. The list contains the names of columns in the index.csv file that hold the location of images for each channel. DeepProfiler assumes each channel is stored as a separate image, and also that the path listed in the index.csv file is relative to the input/images directory (instead of absolute paths). This facilitates moving the project to another machine in a different location.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">file_format</span></code>: <em>(string)</em> extension of image files, e.g. tiff, tif, png.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bits</span></code>: <em>(int)</em> pixel bit depth. Not necessary for any analysis, only used for compression purposes. 8-bit and 16-bit images are currently supported.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">width</span></code>: <em>(int)</em> width of the input image in pixels</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">height</span></code>: <em>(int)</em> height of the input image in pixels</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">locations</span></code>: parameterize the way in which DeepProfiler will search for single cells in images for training and for profiling.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">mode</span></code>: <em>(string)</em> this field indicates if images will be processed at single cell resolution or in full image mode. It only accepts two strings: <code class="docutils literal notranslate"><span class="pre">single_cells</span></code> - activates single-cell analysis mode, thus, requiring cell locations to be stored in the <code class="docutils literal notranslate"><span class="pre">inputs/locations/</span></code> folder (Section XXX); <code class="docutils literal notranslate"><span class="pre">full_image</span></code> - activates full image analysis (no need for locations files).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">box_size</span></code>: <em>(int)</em> specifies the size in pixels of the bounding box used to crop single cells out of images. The value is used for both the width and the height of the box (a square box). This value is used even in <code class="docutils literal notranslate"><span class="pre">full_image</span></code> mode, in which case the image will be resized to these dimensions. Note that DeepProfiler enforces a fixed input size because that is what neural network models usually expect. The box size should be selected to fully cover a typical cell in the experiment. It is OK if large cells are cut a bit, as long as this is relatively rare compared to the normal cell size. Also, it is OK if cells appear with neighboring cells in the same box, which we call “single cells in context” or can be fixed by masking (see below).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">view_size</span></code>: <em>(int)</em> useful only in <code class="docutils literal notranslate"><span class="pre">full_image</span></code> mode, specifies the size in pixels of the region of the image to be covered by cropping before resizing to the dimensions configured in <code class="docutils literal notranslate"><span class="pre">box_size</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mask_objects</span></code>: <em>(bool)</em> true or false, indicates whether cells should be masked using the cell outlines in <code class="docutils literal notranslate"><span class="pre">input/outlines</span></code>. Optional, the recommended value at the moment is false (see more information below).</p></li>
</ul>
</li>
</ul>
</section>
<section id="prepare-configuration-for-illumination-correction-and-compression">
<h3>2. <code class="docutils literal notranslate"><span class="pre">prepare</span></code>: configuration for illumination correction and compression<a class="headerlink" href="#prepare-configuration-for-illumination-correction-and-compression" title="Permalink to this headline">#</a></h3>
<p>The command <code class="docutils literal notranslate"><span class="pre">prepare</span></code> then runs illumination correction and compression, useful for preparing training datasets that can be read efficiently repeated times from disk. This is optional if you only need to do feature extraction and profiling with a pre-trained model.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">illumination_correction</span></code>: parameters to run a prospective illumination correction algorithm that estimates the illumination correction functions for each channel in each plate.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">down_scale_factor</span></code>: <em>(float)</em> the illumination correction functions are not computed at full resolution. This parameter tells DeepProfiler how small these functions should be. A common parameter is 4, for images of about 1024x1024 pixels, resulting in illumination correction functions of 256x256 pixels.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">median_filter_size</span></code>: <em>(int)</em> size in pixels of the smoothing operator applied before aggregation of the illumination correction function. Usually set to 24 for images of 1024x1024 pixels.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">compression</span></code>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">implement</span></code>: <em>(bool)</em> true or false, whether compression is used for training and profiling. If true, other DeepProfiler commands will use the compressed images in the <code class="docutils literal notranslate"><span class="pre">output/compressed/</span></code> directory instead of the original images in the <code class="docutils literal notranslate"><span class="pre">input/images/</span></code> directory.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scaling_factor</span></code>: <em>(float)</em> make images a fraction of what they are. 1.0 means no scaling, 0.8 means resize to 80% of the current size in x and y. Re-scaling images results in smaller files that are faster to read during training, but loses spatial resolution, which is generally not recommended. Use a value different to 1.0 only if there is a good experimental reason.</p></li>
</ul>
</li>
</ul>
</section>
<section id="train-parameters-for-training-a-deep-learning-model-on-your-data">
<h3>3. <code class="docutils literal notranslate"><span class="pre">train</span></code>: parameters for training a deep learning model on your data.<a class="headerlink" href="#train-parameters-for-training-a-deep-learning-model-on-your-data" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">partition</span></code>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">targets</span></code>: <em>(array)</em> column names in the metadata (<code class="docutils literal notranslate"><span class="pre">index.csv</span></code> file) that want to be used as classification targets for training the neural networks. It currently uses only the first element in the list, e.g., <code class="docutils literal notranslate"><span class="pre">['Compound',</span> <span class="pre">'Concentration']</span></code>, means that there are two columns in the <code class="docutils literal notranslate"><span class="pre">index.csv</span> </code>file with that information, and that DeepProfiler will use <code class="docutils literal notranslate"><span class="pre">'Compound'</span></code> for training. The rest of the array is currently ignored, but is intended to be used in the future. If both columns are necessary for training, consider merging them in a single column, otherwise you can leave only one column name in the array i.e., <code class="docutils literal notranslate"><span class="pre">['Compound']</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">split_field</span></code>: <em>(string)</em> column name in the <code class="docutils literal notranslate"><span class="pre">index.csv</span></code> file that indicates which images should be used for training and which ones for validation (or just ignored). This column may be one of the columns containing information about the experiment (e.g. plate id) or a custom-defined column with these decisions made by the analysis.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">training</span></code>: <em>(array)</em> unique values in the <code class="docutils literal notranslate"><span class="pre">split_field</span></code> column of the <code class="docutils literal notranslate"><span class="pre">index.csv</span></code> file that indicate which images will be used for training. For example, if <code class="docutils literal notranslate"><span class="pre">split_field=Metadata_Plate</span></code>, this array should indicate which plates are intended to used for training e.g. <code class="docutils literal notranslate"><span class="pre">[&quot;plateA&quot;,</span> <span class="pre">&quot;plateB&quot;,</span> <span class="pre">&quot;plateC&quot;]</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">validation</span></code>: <em>(array)</em> unique values in the <code class="docutils literal notranslate"><span class="pre">split_field</span></code> column of the <code class="docutils literal notranslate"><span class="pre">index.csv</span></code> file that indicate which images will be used for validation. This is the same as the <code class="docutils literal notranslate"><span class="pre">training</span></code> field above.</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">model</span></code>: deep learning model parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: <em>(string)</em> deep learning model to be used, the name should be one of the models in the plugins folder. The default recommended model is <code class="docutils literal notranslate"><span class="pre">efficientnet</span></code> for weakly supervised learning. We also support <code class="docutils literal notranslate"><span class="pre">resnet</span></code> models.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">crop_generator</span></code>: <em>(string)</em> strategy for cropping single cells from images. Crop generators are implemented in the plugins folder and can be extended with custom code if necessary. DeepProfiler currently has the following options implemented: 1) <code class="docutils literal notranslate"><span class="pre">sampled_crop_generator</span></code>, this crop generator reads single-cell images pre-cropped and exported for training (see Section XXX). This is the recommended way for training new models.  2) <code class="docutils literal notranslate"><span class="pre">online_labels_cropgen</span></code>, used for training with online label smoothing using exported single-cell datasets as before. If analyzing the dataset in full_image mode, you should use the default value. 3) <code class="docutils literal notranslate"><span class="pre">repeat_channel_crop_generator</span></code>, used for extracting features using networks pre-trained with the ImageNet dataset (RGB natural images). This crop generator transforms each gray-scale channel of your images into an RGB image to enable processing, and then concatenates the features of all channels in a single vector. This crop generator is only useful for profiling and should not be used for training. It can be used in <code class="docutils literal notranslate"><span class="pre">full_image</span></code> analysis mode. 4)  <code class="docutils literal notranslate"><span class="pre">full_image_crop_generator</span></code>, used for training new models and profiling in full image mode.</p></li>
<li><p><code>augmentations</code>: <em>(boolean)</em> </code>switch augmentation layer on and off. DeepProfiler uses data augmentation to generate models robust to certain transformations and noise. The transformations implemented in the augmentation layer are applied at random to images of single cells during training only, and include: 90 degree rotations, horizontal flips, brightness and contrast illumination perturbations on each channel separately.</p></li>
<li><p><code>metrics</code>: <em>(array of strings)</em> contains names of metrics to monitor performance during training. It supports most of the <a class="reference external" href="https://keras.io/api/metrics/">keras metrics</a>, including <code>accuracy</code>. This applies for now only for the <code>train</code> command.</p></li>
<li><p><code>epochs</code>: <em>(int)</em> number of epochs for training.</p></li>
<li><p><code>initialization</code>: <em>(string)</em> strategy to set the initial model weights for training. Valid values are <code>Random</code> (supported by all models) or <code>ImageNet</code> (currently supported by ResNet and EfficientNet models only). Using ImageNet weights is a better initialization strategy in practice, and usually leads to improved performance.</p></li>
<li><p><code>checkpoint_policy</code>: <em>(string)</em> or <em>(int)</em> checkpointing policy parameter (optional). Checkpoints are files that save the state of the model during training, because training sessions are usually long and may fail (or be interrupted by the system). Checkpoints help to recover the training session, or simply reuse the model after training. If the parameter is an integer number, then DeepProfiler saves model checkpoints every <code>checkpoint_policy</code> step. If the string <code>best</code> is used, then DeepProfiler saves only the best-performed checkpoint according to validation performance. By default, checkpoints are saved for every epoch.</p></li>
<li><p><code>params</code>: model-specific values that depend on the plugin or architecture.</p>
<ul>
<li><p><code>learning_rate</code>: <em>(float)</em> initial learning rate for the optimizer.</p></li>
<li><p><code>batch_size</code>: <em>(int)</em> number of samples per batch during training.</p></li>
<li><p><code>conv_blocks</code>: <em>(int)</em> number of layers, or convolutional blocks. For ResNet valid values only include <code>50</code>, <code>101</code> and <code>152</code>.</p></li>
<li><p><code>label_smoothing</code>:<code> </code>(<em>float</em>) label smoothing parameter for categorical cross entropy loss.</p></li>
<li><p><code>online_label_smoothing:</code>(<em>float</em>) label smoothing if online labeling is used.</p></li>
<li><p><code>online_lambda:</code> (<em>float</em>) online labeling regularization parameter.</p></li>
</ul>
</li>
<li><p><code>lr_schedule</code>: <em>(array or string)</em> strategy for decreasing the learning rate during training. There are three strategies supported:</p>
<ul>
<li><ol class="simple">
<li><p>constant rate, which doesn’t require this parameter to be set (i.e. just remove this parameter from the config file).</p></li>
</ol>
</li>
<li><ol class="simple">
<li><p>step schedule: changes the learning rate to a desired value at specific epochs. This strategy needs you to configure two arrays, ”epoch” for the epochs where the learning rate will be changed (integer numbers), and “lr” with the actual desired learning rate values (e.g. <code>{“epoch”:[40, 80], “lr”:[0.1, 0.01]}</code>). Both arrays are expected to be the same size.</p></li>
</ol>
</li>
<li><ol class="simple">
<li><p>cosine decay, which increments the learning rate from zero to the initial learning rate using a linear function during the first five epochs. After that, every epoch reduces the learning rate according to the cosine decay. Use <code>”cosine”</code> to enable this option.</p></li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
<li><p><code>sampling</code>: parameters to load images and crop single cells during training. Those parameters are only used for the default <code>crop_generator</code> (<code>”crop_generator”)</code>, which is used for exporting single cells, among others.</p>
<ul>
<li><p><code>factor</code>: <em>(float)</em> fraction of crops from each image to be used for training (number between 0 and 1). This parameter can be used to prevent filling up the queue with example cells from a few images only. With a small sampling factor, the queue will have more diversity of cells cropped from a variety of images to create batches, improving the training performance. In this case, more epochs will be needed to reach optimal performance.</p></li>
<li><p><code>cache_size</code>: <em>(int)</em> number of examples to keep in memory from the sampling process. The larger the better to ensure diversity of examples for creating training batches. This needs to be set according to hardware capabilities, number of channels, box size, etc.</p></li>
<li><p><code>workers</code>: <em>(int)</em> number of parallel loading processes that read images, crop single cells and put them in the queue for training.</p></li>
</ul>
</li>
<li><p><code>validation</code>: parameters for experimental evaluation.</p>
<ul>
<li><p><code>frequency</code>: <em>(int)</em> number of epochs to run before running one validation evaluation.</p></li>
<li><p><code>top_k</code>: <em>(int)</em> reports an accuracy metric where the correct answer is in the top K choices.</p></li>
<li><p><code>batch_size</code>: <em>(int)</em> batch size for the validation set.</p></li>
<li><p><code>frame</code>: <em>(string)</em> partition of the data used for validation. Valid values include “all”, “train” or “val”. Recommended default value: “val”.</p></li>
<li><p><code>sample_first_crops</code>: <em>(bool)</em> true or false, whether to use all crops from each validation image or only sample the first N for validation, where N is the batch size.</p></li>
</ul>
</li>
</ul>
</section>
<section id="code-profile-code-parameters-to-run-an-existing-model-on-images-to-extract-features-or-obtain-classification-outputs">
<h3>4. <code>profile</code>: parameters to run an existing model on images to extract features or obtain classification outputs.<a class="headerlink" href="#code-profile-code-parameters-to-run-an-existing-model-on-images-to-extract-features-or-obtain-classification-outputs" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p><code>use_pretrained_input_size</code>: <em>(int)</em> input size for the neural network models pre-trained on the ImageNet dataset. The pretrained InceptionResNetv2 model uses <code>299</code> while pretrained ResNet and EfficientNet models use <code>224</code>. This parameter is not needed for models trained by you, only for these three supported pretrained models.</p></li>
<li><p><code>feature_layer</code>: <em>(string)</em> name of the layer in the convolutional network to be used for feature extraction.</p></li>
<li><p><code>checkpoint</code>: <em>(string)</em> name of the weights file stored in the <code>outputs/&lt;experiment&gt;/checkpoint/</code> directory after the network is trained.</p></li>
<li><p><code>batch_size</code>: <em>(int)</em> number of samples used during the forward pass for feature extraction.</p></li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="04-metadata.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">4. Metadata files</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="06-train.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">6. Training models with DeepProfiler</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Michael Bornholdt, Juan Caicedo, Yu Han, Nikita Moshkov, Rebecca Senft (in alphabetical order)<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>